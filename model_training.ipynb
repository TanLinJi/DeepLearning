{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638cf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# 1. 准备训练数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "      train=True, \n",
    "      transform=torchvision.transforms.ToTensor(), \n",
    "      download=True\n",
    ")\n",
    "\n",
    "# 2. 准备测试数据集\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='./datasets',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_data_size = len(train_data) # 训练数据集的大小 50000张\n",
    "test_data_size = len(test_data)   # 测试数据集的大小 10000张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab1196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 3. 利用Dataloader 加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b3f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# 4. 搭建神经网络\n",
    "# 因为 CIRAR10 是一个 10 分类的数据集，所以输出的类别是 10 个\n",
    "# 这个可以单独放到一个文件中，比如model.py，然后导入这个包\n",
    "class TuDui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TuDui, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fcefab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 插一嘴， 如何验证自己模型是否正确\n",
    "# 通常是通过判断输入指定的尺寸，看看输出的尺寸是否和预期一致\n",
    "\n",
    "if __name__=='__main__':\n",
    "    tudui = TuDui()\n",
    "    input = torch.ones((64, 3, 32, 32))\n",
    "    output = tudui(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2426ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 创建网络模型\n",
    "tudui = TuDui()\n",
    "\n",
    "# 6. 创建损失函数\n",
    "loss_function = nn.CrossEntropyLoss()  # CrossEntropyLoss这个损失常用于分类问题\n",
    "\n",
    "# 7. 创建优化器\n",
    "learning_rate = 0.001 # 学习率， 这个通常单独作为一个变量传入优化器,  便于修改\n",
    "optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceddb962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------第 1 轮训练开始-----------------\n",
      "训练次数：100，Loss：2.3047\n",
      "训练次数：200，Loss：2.3278\n",
      "训练次数：300，Loss：2.2822\n",
      "训练次数：400，Loss：2.3127\n",
      "训练次数：500，Loss：2.3030\n",
      "训练次数：600，Loss：2.2924\n",
      "训练次数：700，Loss：2.2948\n",
      "整体测试集上的Loss:360.6908.\n",
      "-----------------第 2 轮训练开始-----------------\n",
      "训练次数：800，Loss：2.2980\n",
      "训练次数：900，Loss：2.2949\n",
      "训练次数：1000，Loss：2.3059\n",
      "训练次数：1100，Loss：2.3011\n",
      "训练次数：1200，Loss：2.2956\n",
      "训练次数：1300，Loss：2.2854\n",
      "训练次数：1400，Loss：2.3018\n",
      "训练次数：1500，Loss：2.2958\n",
      "整体测试集上的Loss:359.3499.\n",
      "-----------------第 3 轮训练开始-----------------\n",
      "训练次数：1600，Loss：2.3011\n",
      "训练次数：1700，Loss：2.2785\n",
      "训练次数：1800，Loss：2.2982\n",
      "训练次数：1900，Loss：2.2716\n",
      "训练次数：2000，Loss：2.2741\n",
      "训练次数：2100，Loss：2.2846\n",
      "训练次数：2200，Loss：2.2664\n",
      "训练次数：2300，Loss：2.2660\n",
      "整体测试集上的Loss:357.4979.\n",
      "-----------------第 4 轮训练开始-----------------\n",
      "训练次数：2400，Loss：2.2880\n",
      "训练次数：2500，Loss：2.2897\n",
      "训练次数：2600，Loss：2.2698\n",
      "训练次数：2700，Loss：2.2657\n",
      "训练次数：2800，Loss：2.2784\n",
      "训练次数：2900，Loss：2.2688\n",
      "训练次数：3000，Loss：2.2572\n",
      "训练次数：3100，Loss：2.2605\n",
      "整体测试集上的Loss:354.1559.\n",
      "-----------------第 5 轮训练开始-----------------\n",
      "训练次数：3200，Loss：2.2294\n",
      "训练次数：3300，Loss：2.2536\n",
      "训练次数：3400，Loss：2.2294\n",
      "训练次数：3500，Loss：2.2247\n",
      "训练次数：3600，Loss：2.2434\n",
      "训练次数：3700，Loss：2.2314\n",
      "训练次数：3800，Loss：2.1996\n",
      "训练次数：3900，Loss：2.1956\n",
      "整体测试集上的Loss:347.1752.\n",
      "-----------------第 6 轮训练开始-----------------\n",
      "训练次数：4000，Loss：2.2412\n",
      "训练次数：4100，Loss：2.1889\n",
      "训练次数：4200，Loss：2.1571\n",
      "训练次数：4300，Loss：2.2410\n",
      "训练次数：4400，Loss：2.2096\n",
      "训练次数：4500，Loss：2.1921\n",
      "训练次数：4600，Loss：2.1608\n",
      "整体测试集上的Loss:337.5174.\n",
      "-----------------第 7 轮训练开始-----------------\n",
      "训练次数：4700，Loss：2.1196\n",
      "训练次数：4800，Loss：2.2288\n",
      "训练次数：4900，Loss：2.1014\n",
      "训练次数：5000，Loss：2.0845\n",
      "训练次数：5100，Loss：2.0357\n",
      "训练次数：5200，Loss：2.0780\n",
      "训练次数：5300，Loss：2.0432\n",
      "训练次数：5400，Loss：2.0514\n",
      "整体测试集上的Loss:327.1284.\n",
      "-----------------第 8 轮训练开始-----------------\n",
      "训练次数：5500，Loss：2.0388\n",
      "训练次数：5600，Loss：1.9555\n",
      "训练次数：5700，Loss：2.1117\n",
      "训练次数：5800，Loss：1.9480\n",
      "训练次数：5900，Loss：2.1036\n",
      "训练次数：6000，Loss：2.0971\n",
      "训练次数：6100，Loss：1.9254\n",
      "训练次数：6200，Loss：1.8681\n",
      "整体测试集上的Loss:313.6715.\n",
      "-----------------第 9 轮训练开始-----------------\n",
      "训练次数：6300，Loss：1.9520\n",
      "训练次数：6400，Loss：1.8514\n",
      "训练次数：6500，Loss：2.1627\n",
      "训练次数：6600，Loss：2.0112\n",
      "训练次数：6700，Loss：1.9280\n",
      "训练次数：6800，Loss：1.8957\n",
      "训练次数：6900，Loss：2.0209\n",
      "训练次数：7000，Loss：1.9126\n",
      "整体测试集上的Loss:307.7595.\n",
      "-----------------第 10 轮训练开始-----------------\n",
      "训练次数：7100，Loss：2.0683\n",
      "训练次数：7200，Loss：1.9031\n",
      "训练次数：7300，Loss：2.0629\n",
      "训练次数：7400，Loss：1.7614\n",
      "训练次数：7500，Loss：2.0234\n",
      "训练次数：7600，Loss：1.9099\n",
      "训练次数：7700，Loss：1.9795\n",
      "训练次数：7800，Loss：1.8903\n",
      "整体测试集上的Loss:303.6027.\n"
     ]
    }
   ],
   "source": [
    "# 8. 设置训练网络的一些参数\n",
    "total_train_step = 0  # 记录训练的总次数\n",
    "total_test_step = 0   # 记录测试的总次数\n",
    "epoch = 10            # 训练的轮数\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------------第 {} 轮训练开始-----------------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        img, target = data\n",
    "        output = tudui(img) # 投喂到神经网络中得到一个输出\n",
    "        loss = loss_function(output, target)  # 计算损失（预测输出和真实值之间的关系）\n",
    "\n",
    "        # 开始优化（利用优化器优化模型）\n",
    "        optimizer.zero_grad()  # 优化之前一定要先把梯度清零\n",
    "        loss.backward()   # 利用损失函数的反向传播，得到每个参数节点的梯度\n",
    "        optimizer.step()  # 对其中的参数进行一个优化\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，Loss：{:.4f}\".format(total_train_step, loss.item()))\n",
    "\n",
    "    # 上边是完整的一轮训练流程\n",
    "    # 当一轮训练结束后，如何来判断训练的结果到底怎么样，有没有达到预期，需要对训练的结果进行测试\n",
    "    # 根据测试数据集上的正确率/损失，来判断模型有没有训练好\n",
    "    # 测试的过程就不要调优了，需要根据现有模型来测试\n",
    "    total_test_loss = 0  # 本轮测试的总损失\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img, target = data\n",
    "            output = tudui(img) # 将测试数据投喂到网络中\n",
    "            loss = loss_function(output,target)  # 计算模型输出与真实值之间的误差\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "    print(\"整体测试集上的Loss:{:.4f}.\".format(total_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd98d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------第 1 轮训练开始-----------------\n",
      "训练次数：100，Loss：1.2973\n",
      "训练次数：200，Loss：1.4113\n",
      "训练次数：300，Loss：1.4473\n",
      "训练次数：400，Loss：1.3694\n",
      "训练次数：500，Loss：1.3803\n",
      "训练次数：600，Loss：1.4758\n",
      "训练次数：700，Loss：1.5866\n",
      "整体测试集上的Loss:236.5653.\n",
      "模型tudui_1_epoch.pth已保存.\n",
      "-----------------第 2 轮训练开始-----------------\n",
      "训练次数：800，Loss：1.2987\n",
      "训练次数：900，Loss：1.3471\n",
      "训练次数：1000，Loss：1.2790\n",
      "训练次数：1100，Loss：1.5558\n",
      "训练次数：1200，Loss：1.3196\n",
      "训练次数：1300，Loss：1.2222\n",
      "训练次数：1400，Loss：1.4337\n",
      "训练次数：1500，Loss：1.3127\n",
      "整体测试集上的Loss:234.4640.\n",
      "模型tudui_2_epoch.pth已保存.\n",
      "-----------------第 3 轮训练开始-----------------\n",
      "训练次数：1600，Loss：1.3155\n",
      "训练次数：1700，Loss：1.3248\n",
      "训练次数：1800，Loss：1.6011\n",
      "训练次数：1900，Loss：1.4443\n",
      "训练次数：2000，Loss：1.7525\n",
      "训练次数：2100，Loss：1.2563\n",
      "训练次数：2200，Loss：1.1942\n",
      "训练次数：2300，Loss：1.5056\n",
      "整体测试集上的Loss:232.0970.\n",
      "模型tudui_3_epoch.pth已保存.\n",
      "-----------------第 4 轮训练开始-----------------\n",
      "训练次数：2400，Loss：1.5077\n",
      "训练次数：2500，Loss：1.2415\n",
      "训练次数：2600，Loss：1.4628\n",
      "训练次数：2700，Loss：1.4245\n",
      "训练次数：2800，Loss：1.3601\n",
      "训练次数：2900，Loss：1.5050\n",
      "训练次数：3000，Loss：1.2911\n",
      "训练次数：3100，Loss：1.4380\n",
      "整体测试集上的Loss:229.7724.\n",
      "模型tudui_4_epoch.pth已保存.\n",
      "-----------------第 5 轮训练开始-----------------\n",
      "训练次数：3200，Loss：1.2251\n",
      "训练次数：3300，Loss：1.3640\n",
      "训练次数：3400，Loss：1.3096\n",
      "训练次数：3500，Loss：1.5740\n",
      "训练次数：3600，Loss：1.4324\n",
      "训练次数：3700，Loss：1.3565\n",
      "训练次数：3800，Loss：1.3012\n",
      "训练次数：3900，Loss：1.4349\n",
      "整体测试集上的Loss:227.7238.\n",
      "模型tudui_5_epoch.pth已保存.\n",
      "-----------------第 6 轮训练开始-----------------\n",
      "训练次数：4000，Loss：1.3967\n",
      "训练次数：4100，Loss：1.3994\n",
      "训练次数：4200，Loss：1.4954\n",
      "训练次数：4300，Loss：1.2226\n",
      "训练次数：4400，Loss：1.1535\n",
      "训练次数：4500，Loss：1.2951\n",
      "训练次数：4600，Loss：1.5280\n",
      "整体测试集上的Loss:225.4726.\n",
      "模型tudui_6_epoch.pth已保存.\n",
      "-----------------第 7 轮训练开始-----------------\n",
      "训练次数：4700，Loss：1.3315\n",
      "训练次数：4800，Loss：1.4385\n",
      "训练次数：4900，Loss：1.4016\n",
      "训练次数：5000，Loss：1.4534\n",
      "训练次数：5100，Loss：1.0088\n",
      "训练次数：5200，Loss：1.4157\n",
      "训练次数：5300，Loss：1.2991\n",
      "训练次数：5400，Loss：1.4026\n",
      "整体测试集上的Loss:223.3015.\n",
      "模型tudui_7_epoch.pth已保存.\n",
      "-----------------第 8 轮训练开始-----------------\n",
      "训练次数：5500，Loss：1.2834\n",
      "训练次数：5600，Loss：1.3211\n",
      "训练次数：5700，Loss：1.4779\n",
      "训练次数：5800，Loss：1.4248\n",
      "训练次数：5900，Loss：1.3972\n",
      "训练次数：6000，Loss：1.6717\n",
      "训练次数：6100，Loss：1.1904\n",
      "训练次数：6200，Loss：1.1874\n",
      "整体测试集上的Loss:221.1634.\n",
      "模型tudui_8_epoch.pth已保存.\n",
      "-----------------第 9 轮训练开始-----------------\n",
      "训练次数：6300，Loss：1.6335\n",
      "训练次数：6400，Loss：1.2310\n",
      "训练次数：6500，Loss：1.6786\n",
      "训练次数：6600，Loss：1.2929\n",
      "训练次数：6700，Loss：1.2084\n",
      "训练次数：6800，Loss：1.2560\n",
      "训练次数：6900，Loss：1.2248\n",
      "训练次数：7000，Loss：1.1998\n",
      "整体测试集上的Loss:219.0598.\n",
      "模型tudui_9_epoch.pth已保存.\n",
      "-----------------第 10 轮训练开始-----------------\n",
      "训练次数：7100，Loss：1.5169\n",
      "训练次数：7200，Loss：1.2236\n",
      "训练次数：7300，Loss：1.3724\n",
      "训练次数：7400，Loss：1.0984\n",
      "训练次数：7500，Loss：1.3966\n",
      "训练次数：7600，Loss：1.3824\n",
      "训练次数：7700，Loss：1.1040\n",
      "训练次数：7800，Loss：1.4634\n",
      "整体测试集上的Loss:217.0297.\n",
      "模型tudui_10_epoch.pth已保存.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 这是上一个框的改进版本，添加tensorboard\n",
    "\n",
    "# 8. 设置训练网络的一些参数\n",
    "total_train_step = 0  # 记录训练的总次数\n",
    "total_test_step = 0   # 记录测试的总次数\n",
    "epoch = 10            # 训练的轮数\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"./logs_model_training\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------------第 {} 轮训练开始-----------------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        img, target = data\n",
    "        output = tudui(img) # 投喂到神经网络中得到一个输出\n",
    "        loss = loss_function(output, target)  # 计算损失（预测输出和真实值之间的关系）\n",
    "\n",
    "        # 开始优化（利用优化器优化模型）\n",
    "        optimizer.zero_grad()  # 优化之前一定要先把梯度清零\n",
    "        loss.backward()   # 利用损失函数的反向传播，得到每个参数节点的梯度\n",
    "        optimizer.step()  # 对其中的参数进行一个优化\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，Loss：{:.4f}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), global_step=total_train_step)\n",
    "\n",
    "    # 上边是完整的一轮训练流程\n",
    "    # 当一轮训练结束后，如何来判断训练的结果到底怎么样，有没有达到预期，需要对训练的结果进行测试\n",
    "    # 根据测试数据集上的正确率/损失，来判断模型有没有训练好\n",
    "    # 测试的过程就不要调优了，需要根据现有模型来测试\n",
    "    total_test_loss = 0  # 本轮测试的总损失\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img, target = data\n",
    "            output = tudui(img) # 将测试数据投喂到网络中\n",
    "            loss = loss_function(output,target)  # 计算模型输出与真实值之间的误差\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "    print(\"整体测试集上的Loss:{:.4f}.\".format(total_test_loss))\n",
    "\n",
    "    total_test_step = total_test_step + 1\n",
    "    writer.add_scalar('test_loss',total_test_loss, global_step=total_test_step)\n",
    "\n",
    "    torch.save(tudui, \"./models/tudui_{}_epoch.pth\".format(i+1))\n",
    "    print(\"模型tudui_{}_epoch.pth已保存.\".format(i+1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6488eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------第 1 轮训练开始-----------------\n",
      "训练次数：100，Loss：2.3030\n",
      "训练次数：200，Loss：2.3197\n",
      "训练次数：300，Loss：2.2996\n",
      "训练次数：400，Loss：2.3178\n",
      "训练次数：500，Loss：2.3074\n",
      "训练次数：600，Loss：2.2960\n",
      "训练次数：700，Loss：2.3098\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_1_epoch.pth已保存.\n",
      "-----------------第 2 轮训练开始-----------------\n",
      "训练次数：800，Loss：2.3038\n",
      "训练次数：900，Loss：2.2942\n",
      "训练次数：1000，Loss：2.3042\n",
      "训练次数：1100，Loss：2.3010\n",
      "训练次数：1200，Loss：2.3160\n",
      "训练次数：1300，Loss：2.3045\n",
      "训练次数：1400，Loss：2.3184\n",
      "训练次数：1500，Loss：2.3013\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_2_epoch.pth已保存.\n",
      "-----------------第 3 轮训练开始-----------------\n",
      "训练次数：1600，Loss：2.3074\n",
      "训练次数：1700，Loss：2.3112\n",
      "训练次数：1800，Loss：2.3269\n",
      "训练次数：1900，Loss：2.2939\n",
      "训练次数：2000，Loss：2.3000\n",
      "训练次数：2100，Loss：2.3149\n",
      "训练次数：2200，Loss：2.2985\n",
      "训练次数：2300，Loss：2.2905\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_3_epoch.pth已保存.\n",
      "-----------------第 4 轮训练开始-----------------\n",
      "训练次数：2400，Loss：2.3261\n",
      "训练次数：2500，Loss：2.3088\n",
      "训练次数：2600，Loss：2.2983\n",
      "训练次数：2700，Loss：2.3013\n",
      "训练次数：2800，Loss：2.3045\n",
      "训练次数：2900，Loss：2.2929\n",
      "训练次数：3000，Loss：2.2984\n",
      "训练次数：3100，Loss：2.3056\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_4_epoch.pth已保存.\n",
      "-----------------第 5 轮训练开始-----------------\n",
      "训练次数：3200，Loss：2.3047\n",
      "训练次数：3300，Loss：2.3018\n",
      "训练次数：3400，Loss：2.3146\n",
      "训练次数：3500，Loss：2.2988\n",
      "训练次数：3600，Loss：2.3094\n",
      "训练次数：3700，Loss：2.3092\n",
      "训练次数：3800，Loss：2.3060\n",
      "训练次数：3900，Loss：2.2941\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_5_epoch.pth已保存.\n",
      "-----------------第 6 轮训练开始-----------------\n",
      "训练次数：4000，Loss：2.3135\n",
      "训练次数：4100，Loss：2.2963\n",
      "训练次数：4200，Loss：2.3066\n",
      "训练次数：4300，Loss：2.3364\n",
      "训练次数：4400，Loss：2.3272\n",
      "训练次数：4500，Loss：2.2966\n",
      "训练次数：4600，Loss：2.3166\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_6_epoch.pth已保存.\n",
      "-----------------第 7 轮训练开始-----------------\n",
      "训练次数：4700，Loss：2.2981\n",
      "训练次数：4800，Loss：2.2933\n",
      "训练次数：4900，Loss：2.3189\n",
      "训练次数：5000，Loss：2.2860\n",
      "训练次数：5100，Loss：2.3023\n",
      "训练次数：5200，Loss：2.3098\n",
      "训练次数：5300，Loss：2.2975\n",
      "训练次数：5400，Loss：2.3042\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_7_epoch.pth已保存.\n",
      "-----------------第 8 轮训练开始-----------------\n",
      "训练次数：5500，Loss：2.2876\n",
      "训练次数：5600，Loss：2.3151\n",
      "训练次数：5700，Loss：2.3119\n",
      "训练次数：5800，Loss：2.3081\n",
      "训练次数：5900，Loss：2.2968\n",
      "训练次数：6000，Loss：2.3171\n",
      "训练次数：6100，Loss：2.3014\n",
      "训练次数：6200，Loss：2.3026\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_8_epoch.pth已保存.\n",
      "-----------------第 9 轮训练开始-----------------\n",
      "训练次数：6300，Loss：2.3180\n",
      "训练次数：6400，Loss：2.3136\n",
      "训练次数：6500，Loss：2.3193\n",
      "训练次数：6600，Loss：2.3027\n",
      "训练次数：6700，Loss：2.2945\n",
      "训练次数：6800，Loss：2.2852\n",
      "训练次数：6900，Loss：2.3032\n",
      "训练次数：7000，Loss：2.3081\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_9_epoch.pth已保存.\n",
      "-----------------第 10 轮训练开始-----------------\n",
      "训练次数：7100，Loss：2.2932\n",
      "训练次数：7200，Loss：2.2960\n",
      "训练次数：7300，Loss：2.3018\n",
      "训练次数：7400，Loss：2.3137\n",
      "训练次数：7500，Loss：2.3076\n",
      "训练次数：7600，Loss：2.3126\n",
      "训练次数：7700，Loss：2.2998\n",
      "训练次数：7800，Loss：2.3132\n",
      "整体测试集上的Loss:361.9065.\n",
      "整体测试集上的准确度ACC:0.10700000077486038\n",
      "模型tudui_10_epoch.pth已保存.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 这是上一个框的改进版本，添加tensorboard，又添加了整体正确率\n",
    "\n",
    "# 8. 设置训练网络的一些参数\n",
    "total_train_step = 0  # 记录训练的总次数\n",
    "total_test_step = 0   # 记录测试的总次数\n",
    "epoch = 10            # 训练的轮数\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"./logs_model_training\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------------第 {} 轮训练开始-----------------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        img, target = data\n",
    "        output = tudui(img) # 投喂到神经网络中得到一个输出\n",
    "        loss = loss_function(output, target)  # 计算损失（预测输出和真实值之间的关系）\n",
    "\n",
    "        # 开始优化（利用优化器优化模型）\n",
    "        optimizer.zero_grad()  # 优化之前一定要先把梯度清零\n",
    "        loss.backward()   # 利用损失函数的反向传播，得到每个参数节点的梯度\n",
    "        optimizer.step()  # 对其中的参数进行一个优化\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，Loss：{:.4f}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), global_step=total_train_step)\n",
    "\n",
    "    # 上边是完整的一轮训练流程\n",
    "    # 当一轮训练结束后，如何来判断训练的结果到底怎么样，有没有达到预期，需要对训练的结果进行测试\n",
    "    # 根据测试数据集上的正确率/损失，来判断模型有没有训练好\n",
    "    # 测试的过程就不要调优了，需要根据现有模型来测试\n",
    "    total_test_loss = 0  # 本轮测试的总损失\n",
    "    total_accuracy = 0  # 整体的正确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img, target = data\n",
    "            output = tudui(img) # 将测试数据投喂到网络中\n",
    "            loss = loss_function(output,target)  # 计算模型输出与真实值之间的误差\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = (output.argmax(1) == target).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "    print(\"整体测试集上的Loss:{:.4f}.\".format(total_test_loss))\n",
    "    print(\"整体测试集上的准确度ACC:{:.4%}\".format(total_accuracy/test_data_size))\n",
    "\n",
    "    total_test_step = total_test_step + 1\n",
    "    writer.add_scalar('test_loss',total_test_loss, global_step=total_test_step)\n",
    "    writer.add_scalar('test_accuracy',total_accuracy, global_step=total_test_step)\n",
    "\n",
    "    torch.save(tudui, \"./models/tudui_{}_epoch.pth\".format(i+1))\n",
    "    print(\"模型tudui_{}_epoch.pth已保存.\".format(i+1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 这是上一个框的改进版本，添加tensorboard，又添加了整体正确率， 最后优化\n",
    "\n",
    "# 8. 设置训练网络的一些参数\n",
    "total_train_step = 0  # 记录训练的总次数\n",
    "total_test_step = 0   # 记录测试的总次数\n",
    "epoch = 10            # 训练的轮数\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"./logs_model_training\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------------第 {} 轮训练开始-----------------\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        img, target = data\n",
    "        output = tudui(img) # 投喂到神经网络中得到一个输出\n",
    "        loss = loss_function(output, target)  # 计算损失（预测输出和真实值之间的关系）\n",
    "\n",
    "        # 开始优化（利用优化器优化模型）\n",
    "        optimizer.zero_grad()  # 优化之前一定要先把梯度清零\n",
    "        loss.backward()   # 利用损失函数的反向传播，得到每个参数节点的梯度\n",
    "        optimizer.step()  # 对其中的参数进行一个优化\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，Loss：{:.4f}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar('train_loss', loss.item(), global_step=total_train_step)\n",
    "\n",
    "    # 上边是完整的一轮训练流程\n",
    "    # 当一轮训练结束后，如何来判断训练的结果到底怎么样，有没有达到预期，需要对训练的结果进行测试\n",
    "    # 根据测试数据集上的正确率/损失，来判断模型有没有训练好\n",
    "    # 测试的过程就不要调优了，需要根据现有模型来测试\n",
    "    tudui.eval()        # 许多模型会有这一行，把网络设置为eval状态然后再进行测试\n",
    "    total_test_loss = 0 # 本轮测试的总损失\n",
    "    total_accuracy = 0  # 整体的正确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img, target = data\n",
    "            output = tudui(img) # 将测试数据投喂到网络中\n",
    "            loss = loss_function(output,target)  # 计算模型输出与真实值之间的误差\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = (output.argmax(1) == target).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "    print(\"整体测试集上的Loss:{:.4f}.\".format(total_test_loss))\n",
    "    print(\"整体测试集上的准确度ACC:{:.4%}\".format(total_accuracy/test_data_size))\n",
    "\n",
    "    total_test_step = total_test_step + 1\n",
    "    writer.add_scalar('test_loss',total_test_loss, global_step=total_test_step)\n",
    "    writer.add_scalar('test_accuracy',total_accuracy, global_step=total_test_step)\n",
    "\n",
    "    torch.save(tudui, \"./models/tudui_{}_epoch.pth\".format(i+1))\n",
    "    print(\"模型tudui_{}_epoch.pth已保存.\".format(i+1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b39f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例子，比如有一个2分类问题\n",
    "# input1 --> model --> [0.1, 0.2]  预测在第一个类别上的得分是0.1,在第二个类别上的得分是0,2\n",
    "# input2 --> model --> [0.3, 0.4]  预测在第一个类别上的得分是0.3,在第二个类别上的得分是0.4\n",
    "# 所以对模型而言，他的预测输出是 preds = [1] , [1]   # 代表两个输出都是1类别，(0就是第一个类别，1就是第二个类别)\n",
    "#      假设,数据真实的标签是  targets = [0] , [1]    # 比较预测和真实：preds == targets-->[False, True].sum() = 1 ,这样就可以求出预测正确的个数\n",
    "# 把输出从[0.1, 0.2] [0.3, 0.4] 转换成 [1], [1] 的格式，使用pytorch提供的Argmax()函数-->在横向上，求出最大值所在位置的下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a2c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "outputs = torch.tensor([\n",
    "    [0.1, 0.2],\n",
    "    [0.3, 0.4]\n",
    "    ])\n",
    "\n",
    "outputs.argmax(1)  # 填 1 的时候就是从横向看"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
